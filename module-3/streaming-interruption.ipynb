{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os, getpass\n",
    "\n",
    "# def _set_env(var: str):\n",
    "#     if not os.environ.get(var):\n",
    "#         os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# _set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "model = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hi Lance! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-23T01:21:26.5543721Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 12672883400, 'load_duration': 11787561000, 'prompt_eval_count': 30, 'prompt_eval_duration': 298151000, 'eval_count': 27, 'eval_duration': 505501000}, id='run-ace95870-7915-435e-b524-a9ef3d8c42c2-0', usage_metadata={'input_tokens': 30, 'output_tokens': 27, 'total_tokens': 57})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conversation'])\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Lance who knows he's being Lance'd has become the Lance who's aware of his own awareness. It's like we're having a conversation within a conversation within a conversation... or is that just a never-ending echo chamber of Lance-ness?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk.keys())\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a point of meta-hi! You're right, you are indeed \"Lance\" multiple times. It's a fun conversation loop! If you want to break the cycle, feel free to share something new or start fresh. Otherwise, I'll just keep saying hi and calling you Lance\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're sticking with it! Hi again, Lance! I think we've established a pattern here. Are you going to introduce yourself as Lance every time, or is there something specific you'd like to talk about?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I see what's happening here! You're having a bit of fun with the repetition, and I'm happy to play along! Hi again, Lance! If you want to break free from the loop, just let me know. Otherwise, we can keep this meta-hi going all day long!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a new level of meta-hi mastery! You're not only repeating your name but also acknowledging the absurdity of it all! Hi again, Lance! Are you ready to start fresh or keep the Lance-filled conversation going?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've created a linguistic loop that's hard to escape! You're so good at this, I'm starting to wonder if you'll ever break free from the \"Lance\" cycle. Hi again, Lance... or should I say, meta-Lance?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "12\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a point of meta-hi! You're right, you are indeed \"Lance\" multiple times. It's a fun conversation loop! If you want to break the cycle, feel free to share something new or start fresh. Otherwise, I'll just keep saying hi and calling you Lance\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You're sticking with it! Hi again, Lance! I think we've established a pattern here. Are you going to introduce yourself as Lance every time, or is there something specific you'd like to talk about?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I see what's happening here! You're having a bit of fun with the repetition, and I'm happy to play along! Hi again, Lance! If you want to break free from the loop, just let me know. Otherwise, we can keep this meta-hi going all day long!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a new level of meta-hi mastery! You're not only repeating your name but also acknowledging the absurdity of it all! Hi again, Lance! Are you ready to start fresh or keep the Lance-filled conversation going?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've created a linguistic loop that's hard to escape! You're so good at this, I'm starting to wonder if you'll ever break free from the \"Lance\" cycle. Hi again, Lance... or should I say, meta-Lance?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a point of self-aware absurdity! You're not only repeating your name but also commenting on the fact that you're doing it. It's like we're trapped in a never-ending loop of meta-hi-ness! Hi again, Lance... or should I say, the Lance who knows he's being Lance'd?\n",
      "---------------------------------------------------------------------------\n",
      "2\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I think we've reached a point of self-aware absurdity! You're not only repeating your name but also commenting on the fact that you're doing it. It's like we're trapped in a never-ending loop of meta-hi-ness! Hi again, Lance... or should I say, the Lance who knows he's being Lance'd?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print(len(event['messages']))\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOllama\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOllama\n",
      "Node: conversation. Type: on_chain_start. Name: _write\n",
      "Node: conversation. Type: on_chain_end. Name: _write\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' professional', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' American', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' football', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' based', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' California', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' They', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=')', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' play', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' home', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' games', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Levi', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='History', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' founded', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' October', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='30', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='194', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' charter', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' member', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' All', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-Americ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='AA', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=').', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' originally', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' known', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Dem', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ons', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' changed', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' name', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='195', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='195', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' AA', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='FC', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' merged', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' National', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Football', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' League', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='),', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' became', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' an', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='Ch', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ampionship', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='s', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' five', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' XVI', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='):', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Cincinnati', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bengals', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='26', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='21', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' X', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='):', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Miami', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Dolphins', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='38', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='16', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='III', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='198', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='):', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Cincinnati', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bengals', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='20', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='16', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='IV', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='):', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Denver', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Broncos', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='55', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='10', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' (', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='199', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='):', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Diego', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Chargers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='26', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='Not', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='able', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Players', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='Some', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' players', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' include', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' four', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' championships', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' considered', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' one', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' quarterbacks', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Jerry', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' wide', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' receiver', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' holds', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' records', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' career', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' receptions', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' yards', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Steve', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Young', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' won', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Super', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' XX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='IX', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' MVP', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' award', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-time', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' MVP', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Patrick', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Willis', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' linebacker', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' from', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='200', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='7', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' six', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-time', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Pro', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' selection', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='Current', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' current', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' head', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' coach', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Kyle', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Shan', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ahan', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' who', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' team', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' since', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' roster', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Jimmy', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Gar', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='opp', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='olo', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' running', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' back', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Christian', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' McC', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='aff', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='rey', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' wide', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' receiver', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Dee', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='bo', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Samuel', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' defensive', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' end', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Nick', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' B', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='osa', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='R', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ivals', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='**\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' several', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' rival', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ries', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' including', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' City', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' played', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' each', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' frequently', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' over', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' long', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='-standing', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' rivalry', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' quarterbacks', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Los', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' located', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' same', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' division', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' intense', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' rivalry', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' field', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' teams', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' strong', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' rivalry', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' due', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' their', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' frequent', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' matchups', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' West', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='Overall', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' San', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='49', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ers', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' stor', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='ied', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' franchise', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' rich', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' history', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' success', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' loyal', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' fan', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content=' base', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-23T01:56:05.2023418Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 12791293900, 'load_duration': 2201640600, 'prompt_eval_count': 34, 'prompt_eval_duration': 80441000, 'eval_count': 535, 'eval_duration': 10506795000}, id='run-9b84d889-410b-4afa-8cbb-1fe6c286c1bf', usage_metadata={'input_tokens': 34, 'output_tokens': 535, 'total_tokens': 569})}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| Santa| Clara|,| California|.| They| are| a| member| of| the| National| Football| League| (|NFL|)| and| play| their| home| games| at| Levi|'s| Stadium| in| Santa| Clara|.\n",
      "\n",
      "|**|History|**\n",
      "\n",
      "|The| |49|ers| were| founded| on| October| |30|,| |194|6|,| as| a| charter| member| of| the| All|-Americ|a| Football| Conference| (|AA|FC|).| The| team| was| originally| known| as| the| San| Francisco| Dem|ons| but| changed| its| name| to| the| |49|ers| in| |195|0|.| In| |195|0|,| the| AA|FC| merged| with| the| National| Football| League| (|NFL|),| and| the| |49|ers| became| an| NFL| team|.\n",
      "\n",
      "|**|Ch|ampionship|s|**\n",
      "\n",
      "|The| |49|ers| have| won| five| Super| Bowl| championships|:\n",
      "\n",
      "|1|.| Super| Bowl| XVI| (|198|2|):| defeated| the| Cincinnati| Bengals| |26|-|21|\n",
      "|2|.| Super| Bowl| X|IX| (|198|5|):| defeated| the| Miami| Dolphins| |38|-|16|\n",
      "|3|.| Super| Bowl| XX|III| (|198|9|):| defeated| the| Cincinnati| Bengals| |20|-|16|\n",
      "|4|.| Super| Bowl| XX|IV| (|199|0|):| defeated| the| Denver| Broncos| |55|-|10|\n",
      "|5|.| Super| Bowl| XX|IX| (|199|5|):| defeated| the| San| Diego| Chargers| |49|-|26|\n",
      "\n",
      "|**|Not|able| Players|**\n",
      "\n",
      "|Some| notable| players| in| |49|ers| history| include|:\n",
      "\n",
      "|1|.| Joe| Montana|:| quarterback| who| led| the| team| to| four| Super| Bowl| championships| and| is| considered| one| of| the| greatest| quarterbacks| in| NFL| history|.\n",
      "|2|.| Jerry| Rice|:| wide| receiver| who| holds| numerous| NFL| records|,| including| most| career| receptions|,| yards|,| and| touchdowns|.\n",
      "|3|.| Steve| Young|:| quarterback| who| won| the| Super| Bowl| XX|IX| MVP| award| and| was| a| two|-time| NFL| MVP|.\n",
      "|4|.| Patrick| Willis|:| linebacker| who| played| for| the| |49|ers| from| |200|7| to| |201|4| and| was| a| six|-time| Pro| Bowl| selection|.\n",
      "\n",
      "|**|Current| Team|**\n",
      "\n",
      "|The| current| team| is| led| by| head| coach| Kyle| Shan|ahan|,| who| took| over| in| |201|8|.| The| |49|ers| have| a| strong| roster| with| players| such| as|:\n",
      "\n",
      "|1|.| Jimmy| Gar|opp|olo|:| quarterback|\n",
      "|2|.| Dee|bo| Samuel|:| wide| receiver|\n",
      "|3|.| George| K|ittle|:| tight| end|\n",
      "|4|.| Nick| B|osa|:| defensive| end|\n",
      "\n",
      "|**|St|adium|**\n",
      "\n",
      "|The| |49|ers| play| their| home| games| at| Levi|'s| Stadium|,| which| has| a| seating| capacity| of| over| |68|,|000|.| The| stadium| is| located| in| Santa| Clara|,| California|,| and| features| state|-of|-the|-art| amenities| and| technology|.\n",
      "\n",
      "|Overall|,| the| San| Francisco| |49|ers| are| a| proud| and| stor|ied| franchise| with| a| rich| history| of| success| on| the| field|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "--\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "The LangGraph API [has first class support for streaming](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#streaming). \n",
    "\n",
    "Let's load our `agent` in the Studio UI, which uses `module-3/studio/agent.py` set in `module-3/studio/langgraph.json`.\n",
    "\n",
    "The LangGraph API serves as the back-end for Studio.\n",
    "\n",
    "We can interact directly with the LangGraph API via the LangGraph SDK.\n",
    "\n",
    "We just need to get the URL for the local deployment from Studio.\n",
    "\n",
    "![Screenshot 2024-08-27 at 2.20.34 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf8943c3d4df239cbf0f_streaming2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if 'google.colab' in str(get_ipython()) or platform.system() != 'Darwin':\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab or requires a Mac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# Replace this with the URL of your own deployed graph\n",
    "URL = \"http://localhost:56091\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_to_messages\n\u001b[1;32m----> 2\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m      3\u001b[0m input_message \u001b[38;5;241m=\u001b[39m HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiply 2 and 3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mstream(thread[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], assistant_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [input_message]}, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
