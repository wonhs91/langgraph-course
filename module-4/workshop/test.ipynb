{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "# llm = ChatGroq(model=\"llama-3.2-90b-vision-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class People(BaseModel):\n",
    "  associations: list[str]\n",
    "  \n",
    "class AssociationData(BaseModel):\n",
    "  people: list[str]\n",
    "  places: list[str]\n",
    "\n",
    "class RandomData(BaseModel):\n",
    "  topic_1: str\n",
    "  topic_2: str\n",
    "  Association: AssociationData\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_msg = \"\"\"\n",
    "I want you generate 10 associations between the {topic_1} and the {association}. \n",
    "Generate 10 associations and return them as a list.\n",
    "\n",
    "You MUST not provide any codes. \n",
    "You should only provide the list of associations. \n",
    "\"\"\"\n",
    "\n",
    "llm_association_struct = llm.with_structured_output(People, include_raw=True)\n",
    "people = llm_association_struct.invoke(sys_msg.format(topic_1=\"barber shop\", association=\"people\"))\n",
    "# def generate_association(state):\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were some errors in the parsing \n",
      "error = 1 validation error for People\n",
      "associations\n",
      "  Input should be a valid list [type=list_type, input_value=\"[{'barberShop': 'Barber ...op': 'Barber Shop 10'}]\", input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.9/v/list_type\n"
     ]
    }
   ],
   "source": [
    "if error := people['parsing_error']:\n",
    "  print(f\"There were some errors in the parsing \\n{error = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 validation error for People\n",
       "associations\n",
       "  Input should be a valid list [type=list_type, input_value=\"[{'barberShop': 'Barber ...op': 'Barber Shop 10'}]\", input_type=str]\n",
       "    For further information visit https://errors.pydantic.dev/2.9/v/list_type"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people['parsing_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(associations=['Barber', 'Customer', 'Shop Owner', 'Receptionist', 'Hair Stylist', 'Apprentice', 'Cleaning Staff', 'Manager', 'Security Guard', 'Delivery Person'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class State(BaseModel):\n",
    "  value: str = \"\"\n",
    "  \n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It seems like we just started our conversation and I haven't said anything yet. How can I assist you today?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-27T16:59:58.0609558Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 570613600, 'load_duration': 27706500, 'prompt_eval_count': 30, 'prompt_eval_duration': 71371000, 'eval_count': 24, 'eval_duration': 470186000}, id='run-29cfa769-c2bc-4909-b795-6059def4da86-0', usage_metadata={'input_tokens': 30, 'output_tokens': 24, 'total_tokens': 54})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "llm.invoke([HumanMessage(content=\"What are you saying?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
